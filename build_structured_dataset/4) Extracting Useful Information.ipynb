{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Press Data\n",
    "## 4) Extracting Useful Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import pymongo\n",
    "\n",
    "import pickle\n",
    "import pprint\n",
    "import sortedcontainers\n",
    "\n",
    "import json\n",
    "import bson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Mongo (used to gather more information about the articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb+srv://<username>:<password>@cluster0-uwh3o.mongodb.net/pressdata_db?retryWrites=true&w=majority\")\n",
    "db = client.get_database('pressdata_db')\n",
    "\n",
    "# all the records are part of the \"clippings\" collection\n",
    "records = db.clippings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Import and structure the labelled articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to reorganize and unpack the the Doc objects (labelled articles) from the *labelled_text.bin* file into a dictionary for easier access and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "\n",
    "# unpacks the list of Doc objects from the labelled_text.bin file and returns the dictionary\n",
    "# of the program streams and the list of articles that correspond to each program\n",
    "# each article is represented by a dictionary as described above\n",
    "def unpack_doc_list(doc_list):\n",
    "\n",
    "    doc_dictionary = dict()\n",
    "    \n",
    "    program = None\n",
    "    for doc in doc_list:\n",
    "        if isinstance(doc, str):\n",
    "            if doc.find(\"Start of Article: \") != -1:\n",
    "                article = {'_id': ObjectId(doc.replace(\"Start of Article: \", \"\")), \"text\": []}\n",
    "            elif doc == \"End of Article\":\n",
    "                doc_dictionary[program].append(article)\n",
    "            else:\n",
    "                program = doc\n",
    "                doc_dictionary[program] = []\n",
    "            continue\n",
    "\n",
    "        article['text'].append(doc)\n",
    "\n",
    "    return doc_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the labelled text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/labelled_text.bin','rb') as infile:\n",
    "    doc_list = pickle.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the article dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dictionary = unpack_doc_list(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Create a dictionary of equivalent names\n",
    "\n",
    "To use the dictionary, you use the search word as the key, and the corresponding value will be the standardized word it is equivalent to.\n",
    "\n",
    "For example: searching \"ACOA\" gives \"Atlantic Canada Opportunities Agency\" (and searching \"Atlantic Canada Opportunities Agency\" also gives \"Atlantic Canada Opportunities Agency\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to create the dictionary of equivalencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates and returns a dictionary of equivalent words for the purposes of the BIGS programs\n",
    "# this includes equivalent department names, program names, and the names of provinces and territories\n",
    "def create_equivalency_dictionary():\n",
    "\n",
    "    # read the departments and programs from the \"Departments and Programs\" excel sheet, and list the provinces and territories\n",
    "    dept_list = pd.read_excel(\"./excel_sheets/Departments and Programs.xlsx\", sheet_name = 'Departments').fillna(\"N/A\")\n",
    "    programs_list = pd.read_excel(\"./excel_sheets/Departments and Programs.xlsx\", sheet_name = 'Programs').fillna(\"N/A\")\n",
    "    provinces_and_territories = ['Nova Scotia', 'New Brunswick', 'Prince Edward Island', 'Newfoundland and Labrador', 'Quebec', 'Ontario', 'Manitoba', 'Saskatchewan', 'Alberta', 'British Columbia', 'Yukon', 'Northwest Territories', 'Nunavut']\n",
    "\n",
    "    # create the emptydictionary\n",
    "    equivalencies = dict()\n",
    "\n",
    "    # add equivalent department names\n",
    "    for index, row in dept_list.iterrows():\n",
    "        dept = row['Department']\n",
    "        for category in row:\n",
    "            if category == \"N/A\":\n",
    "                continue\n",
    "            equivalencies[category] = dept\n",
    "\n",
    "    ##### add equivalent program names\n",
    "\n",
    "    # this just finds relevant columns within the Programs excel sheet (some of them are just comments)\n",
    "    relevant_columns = []\n",
    "    for column in programs_list.columns:\n",
    "        if column.find(\"Unnamed\") == -1:\n",
    "            relevant_columns.append(column)\n",
    "    programs_list = programs_list[relevant_columns]\n",
    "\n",
    "    # add the programs to the dictionary\n",
    "    for index, row in programs_list.iterrows():\n",
    "        program = row['Programs']\n",
    "        for category in row:\n",
    "            if category == \"N/A\":\n",
    "                continue\n",
    "            equivalencies[category] = program\n",
    "\n",
    "    #####\n",
    "\n",
    "    # add equivalent province names\n",
    "    equivalencies['PEI'] = 'Prince Edward Island'\n",
    "    \n",
    "    return equivalencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to map a word to its equivalent or standard word using the equivalencies dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the equivalent word to the given word\n",
    "# this simply checks whether the word is contained within the equivalencies dictionary, and \n",
    "# returns the corresponding value if it is, and simply the original word if it's not\n",
    "def equivalency(word):\n",
    "    if word in equivalencies:\n",
    "        return equivalencies[word]\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the equivalency dicationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "equivalencies = create_equivalency_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Building the structured data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all key sentences within the article for each of the given patterns, and calls the \n",
    "# corresponding callback function for each of the sentences\n",
    "# each individual pattern in list_of_patterns must be a list itself with 2 entries of the form \n",
    "# [ list of entity labels, callback function ]\n",
    "# where the list of strings corresponding to the entity labels, and the callback functions take \n",
    "# 3 arguments: the sentence (span object), the paragraph (doc object), and the article id (Mongo Object ID)\n",
    "# returns: void\n",
    "def find_key_sentences(article, list_of_patterns):\n",
    "    \n",
    "    # deconstruct the patterns\n",
    "    # that is, retrieve the lists of target entities labels and the list of corresponding callbacks\n",
    "    list_of_flags = []\n",
    "    list_of_callbacks = []\n",
    "    for pattern in list_of_patterns:\n",
    "        list_of_flags.append(pattern[0])\n",
    "        list_of_callbacks.append(pattern[1])\n",
    "          \n",
    "    # create lists for the types of key sentences and their correpsonding docs\n",
    "    # each list within the list corresponds to a different type of key sentence specified by each \n",
    "    # of the patterns given\n",
    "    # the i^th inner list stores all sentences matching the entity labels of the i^th flag in \n",
    "    # the list list_of_flags\n",
    "    key_sentences = [ list() for x in list_of_flags]\n",
    "    key_docs = [ list() for x in list_of_flags]\n",
    "    \n",
    "    # retrieve the id and the text of the article\n",
    "    oid = article['_id']\n",
    "    text = article['text']\n",
    "    \n",
    "    # find the key sentences in each doc\n",
    "    for doc in text:\n",
    "        \n",
    "        # look at each sentence in the doc\n",
    "        for sent in doc.sents:\n",
    "            \n",
    "            # create a list of all of the different entity labels in the sentence\n",
    "            list_of_ent_labels = []\n",
    "            for ent in sent.ents:\n",
    "                list_of_ent_labels.append(ent.label_)\n",
    "            \n",
    "            if list_of_ent_labels == []:\n",
    "                continue\n",
    "            \n",
    "            # loop through the types of key sentences\n",
    "            for i in range(0, len(key_sentences)):\n",
    "                \n",
    "                # see if the sentence matches the key sentence criteria\n",
    "                if all(x in list_of_ent_labels for x in list_of_flags[i]):\n",
    "                    \n",
    "                    # add the sentence to the corresponding key sentences list\n",
    "                    if sent not in key_sentences[i]:                        \n",
    "                        key_sentences[i].append(sent)\n",
    "                        key_docs[i].append(doc)\n",
    "                    \n",
    "                    # don't allow sentences to be key sentences for multiple criteria\n",
    "                    break\n",
    "    \n",
    "    # call the corresponding callback function for each of the key sentences\n",
    "    for i in range(0, len(key_sentences)):\n",
    "        for j in range(0, len(key_sentences[i])):\n",
    "            list_of_callbacks[i](key_sentences[i][j], key_docs[i][j], oid)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to hold the program stream table data, which is used to create the table \n",
    "program_stream_table = list()\n",
    "\n",
    "# creates a dictionary representing a row in the program stream table, and adds it to the \n",
    "# global variable: program_stream_table\n",
    "# each row contains the program name, the article title, id, publication date, and the \n",
    "# sentence and paragraph by default (however these can be changed)\n",
    "# columns can be adjusted using the column_categories list\n",
    "# input:\n",
    "#   sent - span object\n",
    "#   doc - Doc object\n",
    "#   article_id - Mongo Object ID\n",
    "# returns: void\n",
    "def add_to_program_stream_table(sent, doc, article_id):\n",
    "    \n",
    "    # adjust what columns are included in the table, and also whether duplicates are preserved\n",
    "    column_categories = [\n",
    "        ['GOV_DEPT', False],\n",
    "        ['PROV_GOV', False],\n",
    "        ['MONEY', True],\n",
    "        ['PAYMENT_TYPE', True],\n",
    "        ['ORG', False],\n",
    "    ]\n",
    "    \n",
    "    # create a label dictionary for all entities in the sentence\n",
    "    label_dict = create_label_dictionary(sent)\n",
    "\n",
    "    # get all the program streams mentioned in the sentence\n",
    "    programs = set(label_dict['PROGRAM_STREAM'])\n",
    "            \n",
    "    # create a row in the table for each program stream\n",
    "    for program in programs:\n",
    "        \n",
    "        # find the article on Mongo to incorporate article information\n",
    "        mongo_article = records.find_one({'_id': article_id})\n",
    "        \n",
    "        # represent the data contained in the column_categories object as two separate lists\n",
    "        other_categories = [x[0] for x in column_categories]\n",
    "        keep_duplicates = [x[1] for x in column_categories]\n",
    "        \n",
    "        # create the row\n",
    "        row = dict()\n",
    "        \n",
    "        # add the column information\n",
    "        row['Program'] = program\n",
    "        \n",
    "        for i in range(0, len(other_categories)):\n",
    "            category = other_categories[i]\n",
    "            if category in label_dict:\n",
    "                add_to_row(row, category, label_dict[category], keep_duplicates[i])\n",
    "            else:\n",
    "                row[category] = None  \n",
    "        \n",
    "        row['Sentence'] = sent.text\n",
    "        row['Paragraph'] = doc.text\n",
    "        \n",
    "        row['Publication Date'] = mongo_article['pub_date']\n",
    "        row['Article ID'] = article_id\n",
    "        row['Article'] = mongo_article['title']\n",
    "    \n",
    "        # add the row to the global program_stream_table object\n",
    "        program_stream_table.append(row)\n",
    "\n",
    "    return\n",
    "    \n",
    "# adds a new column to the given row (dictionary) with the given entity label \"category\"\n",
    "# the entries of the column are the new_items which are either stored as a list if duplicates \n",
    "# is True, a set if duplicates is False, or a single value if there is only one object\n",
    "# returns: void\n",
    "def add_to_row(row, category, new_items, duplicates):\n",
    "    if len(new_items) == 1:\n",
    "        row[category] = new_items[0]\n",
    "    elif duplicates:\n",
    "        row[category] = new_items\n",
    "    else:\n",
    "        s = set(new_items)\n",
    "        if len(s) == 1:\n",
    "            row[category] = s.pop()\n",
    "        else:\n",
    "            row[category] = s\n",
    "    \n",
    "    return row\n",
    "\n",
    "# creates and returns a dictionary of the entity labels, and the corresponding entities present\n",
    "# within the given sentence\n",
    "# government collaborations are parsed and put into the PROV_GOV label instead\n",
    "# input: Span object\n",
    "# returns: dictionary\n",
    "def create_label_dictionary(sent):\n",
    "    label_dict = dict()\n",
    "    for ent in sent.ents:\n",
    "        \n",
    "        text = ent.text\n",
    "        label = ent.label_\n",
    "        \n",
    "        if label == 'GOV_COLLAB':\n",
    "            for word in ent:\n",
    "                if word.text in provinces_and_territories:\n",
    "                    text = 'Government of ' + word.text\n",
    "                    label = 'PROV_GOV'\n",
    "                    break\n",
    "        \n",
    "        if label in label_dict:\n",
    "            label_dict[label].append(equivalency(text))\n",
    "        else:\n",
    "            label_dict[label] = [equivalency(text)]\n",
    "    \n",
    "    return label_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function for key sentences with governments collaborations\n",
    "# unimplemented\n",
    "def found_collab_data(sent, doc, article_id):\n",
    "    return\n",
    "  \n",
    "# callback function for key sentences with payment types\n",
    "# unimplemented\n",
    "def found_payment_type(sent, doc, article_id):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    [['PROGRAM_STREAM', 'MONEY'], add_to_program_stream_table],\n",
    "    [['GOV_COLLAB'], found_collab_data],\n",
    "    [['PAYMENT_TYPE'], found_payment_type]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prcessing articles for Accelerated Growth Service\n",
      "Prcessing articles for Advanced Manufacturing Fund\n",
      "Prcessing articles for Aerospace Program\n",
      "Prcessing articles for Agri-Science Clusters\n",
      "Prcessing articles for AgriInnovate Program\n",
      "Prcessing articles for AgriInnovation Program\n",
      "Prcessing articles for AgriMarketing Program\n",
      "Prcessing articles for AgriProcessing Initiative\n",
      "Prcessing articles for AgriScience Program\n",
      "Prcessing articles for Agricultural Clean Technology Program\n",
      "Prcessing articles for Agricultural Greenhouse Gases Program\n",
      "Prcessing articles for Agricultural Innovation Program\n",
      "Prcessing articles for Applied Research and Development Grants\n",
      "Prcessing articles for Aquaculture Collaborative Research and Development Program\n",
      "Prcessing articles for Aquatic and Crop Resource Development\n",
      "Prcessing articles for Atlantic Fisheries Fund\n",
      "Prcessing articles for Atlantic Innovation Fund\n",
      "Prcessing articles for Automotive Innovation Fund\n",
      "Prcessing articles for Automotive Supplier Innovation Fund\n",
      "Prcessing articles for Automotive and Surface Transportation\n",
      "Prcessing articles for British Columbia Salmon Restoration and Innovation Fund\n",
      "Prcessing articles for Build in Canada Innovation Program\n",
      "Prcessing articles for Buildings Infrastructure Program\n",
      "Prcessing articles for Business Development Program\n",
      "Prcessing articles for Business Development and Community Innovation\n",
      "Prcessing articles for Business Innovation\n",
      "Prcessing articles for Business-Led Network Centres of Excellence\n",
      "Prcessing articles for Business-Led Networks of Centres of Excellence\n",
      "Prcessing articles for CANARIE Inc.\n",
      "Prcessing articles for CanExport\n",
      "Prcessing articles for Canada Accelerator and Incubator Program\n",
      "Prcessing articles for Canada Business Network\n",
      "Prcessing articles for Canada Coal Transition Initiative\n",
      "Prcessing articles for Canada Small Business Financing Program\n",
      "Prcessing articles for Canadian Agricultural Adaptation Program\n",
      "Prcessing articles for Canadian Innovation Commercialization Program\n",
      "Prcessing articles for Canadian International Innovation Program\n",
      "Prcessing articles for Canadian Technology Accelerators\n",
      "Prcessing articles for Centre for Drug Research and Development\n",
      "Prcessing articles for Centres of Excellence for Commercialization and Research\n",
      "Prcessing articles for Clean Energy Fund\n",
      "Prcessing articles for Clean Energy for Rural and Remote Communities Program\n",
      "Prcessing articles for Clean Growth Hub\n",
      "Prcessing articles for Clean Growth in the Natural Resource Sectors Innovation Program\n",
      "Prcessing articles for Clean Technology Challenges\n",
      "Prcessing articles for Collaborative Economic Development Projects\n",
      "Prcessing articles for Collaborative Research and Development Grants\n",
      "Prcessing articles for Collaborative Science, Technology and Innovation Program\n",
      "Prcessing articles for College-University Idea to Innovation Grants\n",
      "Prcessing articles for Commercialization and Exports\n",
      "Prcessing articles for Communications Research Centre Canada\n",
      "Prcessing articles for Community Economic Development and Diversification\n",
      "Prcessing articles for Community Futures Program\n",
      "Prcessing articles for Connect Grants\n",
      "Prcessing articles for Construction\n",
      "Prcessing articles for Defence Innovation Research Program\n",
      "Prcessing articles for Developing Innovative Agricultural Products\n",
      "Prcessing articles for Earth Observation Application Development Program\n",
      "Prcessing articles for Eastern Ontario Development Program\n",
      "Prcessing articles for Economic Development Initiative\n",
      "Prcessing articles for Electric Vehicle and Alternative Fuel Infrastructure Deployment Initiative\n",
      "Prcessing articles for Emerging Renewables Power Program\n",
      "Prcessing articles for Energy Efficiency Program\n",
      "Prcessing articles for Energy Innovation Program\n",
      "Prcessing articles for Energy, Mining and Environment\n",
      "Prcessing articles for Engage Grants\n",
      "Prcessing articles for Entrepreneurship and Business Development\n",
      "Prcessing articles for Experience Awards\n",
      "Prcessing articles for Experimental Stream\n",
      "Prcessing articles for Fisheries and Aquaculture Clean Technology Adoption Program\n",
      "Prcessing articles for Forest Innovation Program\n",
      "Prcessing articles for Futurpreneur Canada\n",
      "Prcessing articles for Genome Canada\n",
      "Prcessing articles for GeoConnections\n",
      "Prcessing articles for GeoConnections Program\n",
      "Prcessing articles for Going Global Innovation\n",
      "Prcessing articles for Green Construction Through Wood Program\n",
      "Prcessing articles for Green Jobs - Science and Technology Internship Program\n",
      "Prcessing articles for Growing Forward 2 AgriMarketing Program\n",
      "Prcessing articles for Human Health Therapeutics\n",
      "Prcessing articles for Industrial Research Assistance Program\n",
      "Prcessing articles for Industrial Research Chairs\n",
      "Prcessing articles for Industry-Partnered Collaborative Research\n",
      "Prcessing articles for Information and Communication Technologies\n",
      "Prcessing articles for Innovation Enhancement Grants\n",
      "Prcessing articles for Innovation Superclusters Initiative\n",
      "Prcessing articles for Innovation and Technology Transfer\n",
      "Prcessing articles for Innovation for Defence, Excellence and Security\n",
      "Prcessing articles for Innovative Solutions Canada\n",
      "Prcessing articles for Innovative and Inclusive Economic Ecosystems\n",
      "Prcessing articles for Investing in Business Growth and Productivity\n",
      "Prcessing articles for Investing in Business Innovation\n",
      "Prcessing articles for Investing in Commercialization Partnerships\n",
      "Prcessing articles for Investing in Regional Diversification\n",
      "Prcessing articles for Investments in Forest Industry Transformation\n",
      "Prcessing articles for Low Carbon Economy Challenge\n",
      "Prcessing articles for Medical Devices\n",
      "Prcessing articles for Mining Innovation\n",
      "Prcessing articles for Mitacs Inc.\n",
      "Prcessing articles for Music Entrepreneur Component\n",
      "Prcessing articles for Network Structuring\n",
      "Prcessing articles for New Business Development and Start-Ups\n",
      "Prcessing articles for New Musical Works\n",
      "Prcessing articles for Northern Ontario Development Program\n",
      "Prcessing articles for Ocean, Coastal, and River Engineering\n",
      "Prcessing articles for Oil Spill Response Science Program\n",
      "Prcessing articles for Oil and Gas Clean Tech Program\n",
      "Prcessing articles for Pan North American Renewable Electricity Integration Studies\n",
      "Prcessing articles for Productivity and Expansion\n",
      "Prcessing articles for Productivity, Digitalization and Expansion\n",
      "Prcessing articles for Program of Energy, Research and Development\n",
      "Prcessing articles for Promotion Forest Innovation and Investment\n",
      "Prcessing articles for Proof of Principle Program\n",
      "Prcessing articles for Regional Economic Growth through Innovation\n",
      "Prcessing articles for Regional Growth through Innovation\n",
      "Prcessing articles for Science Horizons Youth Internship Program\n",
      "Prcessing articles for Science and Technology Internship Program\n",
      "Prcessing articles for Smart Grid Deployment Program\n",
      "Prcessing articles for Smart Grid Infrastructure Demonstrations Program\n",
      "Prcessing articles for Space Technology Development Program\n",
      "Prcessing articles for Stem Cell Network\n",
      "Prcessing articles for Strategic Aerospace and Defence Initiative\n",
      "Prcessing articles for Strategic Aerospace and Defence Initiative \n",
      "Prcessing articles for Strategic Innovation Fund\n",
      "Prcessing articles for Strategic Investments in Northern Economic Development\n",
      "Prcessing articles for Strategic Partnership Grants for Networks\n",
      "Prcessing articles for Strategic Partnership Grants for Projects\n",
      "Prcessing articles for Support for Publishers\n",
      "Prcessing articles for Sustainable Development Technology Canada\n",
      "Prcessing articles for Technology Access Centres Grants\n",
      "Prcessing articles for Technology Demonstration Program\n",
      "Prcessing articles for Technology Partnerships Canada\n",
      "Prcessing articles for Temporary Foreign Worker Program\n",
      "Prcessing articles for Trade Commissioner Service\n",
      "Prcessing articles for University Idea to Innovation Grants\n",
      "Prcessing articles for Western Diversification Program\n",
      "Prcessing articles for Western Innovation Initiative\n",
      "Prcessing articles for Women Entrepreneurship Fund\n",
      "Prcessing articles for Women Entrepreneurship Strategy\n",
      "Prcessing articles for Women's Entreprise Initiative\n",
      "Prcessing articles for eHealth Innovations Partnership Program\n",
      "Prcessing articles for ecoENERGY for Renewable Heat\n",
      "Prcessing articles for ecoENERGY for Renewable Power\n",
      "Prcessing articles for ecoEnergy Innovation Initiative\n"
     ]
    }
   ],
   "source": [
    "for program in doc_dictionary:\n",
    "    \n",
    "    print('Prcessing articles for', program)\n",
    "    \n",
    "    articles = doc_dictionary[program]\n",
    "    \n",
    "    for article in articles:\n",
    "        find_key_sentences(article, patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Data Frame of the structured data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(program_stream_table).sort_values(by=['Program'])\n",
    "df_concise = df.sort_values(by=['Program']).set_index(['Program', 'Article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the Data Frame to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./excel_sheets/Program Dataset.xlsx\", index=False)\n",
    "df_concise.to_excel(\"./excel_sheets/Program Dataset (Concise).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Counting the number of entities in each article (Experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that collects and counts the number of entities in each article\n",
    "# input is a list of doc objects, and a list of string representing entities that will be counted\n",
    "# returns: dictionary\n",
    "def count_entities(article, list_of_entities):\n",
    "    \n",
    "    counts = {entity:dict() for entity in list_of_entities}\n",
    "    \n",
    "    for line in article:\n",
    "        for word in line.ents:\n",
    "            label = word.label_\n",
    "            if label in list_of_entities:\n",
    "                word = equivalency(word.text)\n",
    "                if word in counts[label]:\n",
    "                    counts[label][word] += 1\n",
    "                else:\n",
    "                    counts[label][word] = 1\n",
    "   \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article = doc_dictionary[\"Women Entrepreneurship Strategy\"][7]\n",
    "# for line in article['text']:\n",
    "#     displacy.render(line, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_entities = ['FED_GOV', 'PROV_GOV', 'GOV_DEPT', 'PROGRAM_STREAM', 'MONEY', 'PAYMENT_TYPE', 'GPE', 'ORG', 'PROVINCE', 'GOV_COLLAB']\n",
    "    \n",
    "entities = count_entities(article['text'], list_of_entities)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'ORG'\n",
    "pd.DataFrame(entities[label].items(), columns = [label, \"Count\"]).sort_values(by=['Count'], ascending=[False])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
